### 哈希表的原理 Top K 算法详解， MPQ中的Hash算法
```
问题: 海量日志数据, 提取出某日访问百度次数最多的那个IP.

    首先是这一天, 并且是访问百度的日志中的IP取出来, 逐个写入到一个大文件中. 注意到IP是32位的, 最多有2^32个不同的IP(事实上不可能, 得扣去特殊的IP), 在重复量小的情况下, 内存放不下这些不同的IP. 同样可以采用映射的方法, 比如模1000, 把整个大文件映射为1000个小文件, 再找出每个小文件中出现频率最大的IP(可以采用hash_map进行频率统计, 然后再找出频率最大的几个)及相应的频率. 然后再在这1000个最大的IP中, 找出那个频率最大的IP, 即为所求.

具体做法如下：

    按照IP地址的Hash(IP)%1024值, 把海量IP日志分别存储到1024个小文件中.
    对于每一个小文件, 构建一个以IP为key, 出现次数为value的HashMap, 同时记录当前出现次数最多的那个IP地址;
    得到1024个小文件中的出现次数最多的IP, 再依据常规的排序算法得到总体上出现次数最多的IP.
21Hash算法以及暴雪Hash
2015年06月12日 09:08:03 阅读数：1803更多
个人分类： 算法 July文章

一：哈希表简介

    哈希表是一种查找效率极高的数据结构，理想情况下哈希表插入和查找操作的时间复杂度均为O(1)，任何一个数据项可以在一个与哈希表长度无关的时间内计算出一个哈希值（key），然后在常量时间内定位到一个桶（术语bucket，表示哈希表中的一个位置）。当然这是理想情况下，因为任何哈希表的长度都是有限的，所以一定存在不同的数据项具有相同哈希值的情况，此时不同数据项被定为到同一个桶，称为碰撞（collision）。

    哈希表的实现需要解决碰撞问题，碰撞解决大体有两种思路：

    第一种是根据某种原则将被碰撞数据定为到其它桶，例如线性探测——如果数据在插入时发生了碰撞，则顺序查找这个桶后面的桶，将其放入第一个没有被使用的桶；

    第二种策略是每个桶不是一个只能容纳单个数据项的位置，而是一个可容纳多个数据的数据结构（例如链表或红黑树），所有碰撞的数据以某种数据结构的形式组织起来。

    不论使用了哪种碰撞解决策略，都导致插入和查找操作的时间复杂度不再是O(1)。以查找为例，不能通过key定位到桶就结束，必须还要比较原始数据项是否相等，如果不相等，则要使用与插入相同的算法继续查找，直到找到匹配的值或确认数据不在哈希表中。

    使用单链表解决碰撞的哈希表，平均查找复杂度为O(L)，其中L为桶链表的平均长度；而最坏复杂度为O(N)，此时所有数据全部碰撞，哈希表退化成单链表。如下图：

 

二：暴雪的Hash算法(MPQ)

    由一个简单的问题逐步入手：有一个庞大的字符串数组，数组元素就是字符串，然后给定一个单独的字符串，让你从这个数组中查找是否有这个字符串并找到它，你会怎么做？

    有一个方法最简单，老老实实从头查到尾，一个一个比较，直到找到为止，这样做的效率极低。

    最合适的算法自然是使用HashTable（哈希表），可以把一个字符串"压缩" 成一个整数。在暴雪的HASH算法中，两个字符串计算出的Hash值相等的可能非常小，下面看看在MPQ中的Hash算法：

1：函数prepareCryptTable生成一个长度为0x500（合10进制数：1280）的cryptTable[0x500]

 

void prepareCryptTable()  

{   

         unsigned long seed = 0x00100001, index1 = 0, index2 = 0, i;  

  

         for( index1 = 0; index1 < 0x100; index1++ )  

         {   

                  for( index2 = index1, i = 0; i < 5; i++, index2 += 0x100 )  

                  {   

                          unsigned long temp1, temp2;  

  

                          seed = (seed * 125 + 3) % 0x2AAAAB;  

                          temp1 = (seed & 0xFFFF) << 0x10;  

  

                          seed = (seed * 125 + 3) % 0x2AAAAB;  

                          temp2 = (seed & 0xFFFF);  

  

                          cryptTable[index2] = ( temp1 | temp2 );   

                  }   

         }   

}   

 

2：函数HashString计算字符串lpszFileName的hash值，其中dwHashType 为hash的类型。

unsigned long HashString(const char *lpszkeyName, unsigned long dwHashType )  

{  

         unsigned char *key  = (unsigned char *)lpszkeyName;  

         unsigned long seed1 = 0x7FED7FED;  

         unsigned long seed2 = 0xEEEEEEEE;  

         int ch;  

  

         while( *key != 0 )  

         {  

                  ch = *key++;  

                  seed1 = cryptTable[(dwHashType<<8) + ch] ^ (seed1 + seed2);  

                  seed2 = ch + seed1 + seed2 + (seed2<<5) + 3;  

         }  

         return seed1;  

}  

    Blizzard的这个算法是非常高效的，被称为"One-WayHash"( 即通过HASH值反推字符串几乎是不可能的)。举个例子，字符串"unitneutralacritter.grp"通过这个算法得到的结果是0xA26067F3。

    然后是构造一个哈希表来解决问题，哈希表是一个大数组，这个数组的容量根据程序的要求来定义，例如1024。

    每一个Hash值通过取模运算 (mod) 对应到数组中的一个位置，这样，只要比较这个字符串的哈希值对应的位置有没有被占用，就可以得到最后的结果了，

#if 0

想想这是什么速度？是的，是最快的O(1)，现在仔细看看这个算法吧：

typedef struct  

{  

         int nHashA;  

         int nHashB;  

         char bExists;  

         ......  

} SOMESTRUCTRUE;  

  

3：函数GetHashTablePos在Hash表中查找是否存在目标字符串，有则返回要查找字符串的Hash值，否则，return -1.

int GetHashTablePos( char *lpszString, SOMESTRUCTURE *lpTable )   

{   

         //调用上述函数HashString，返回要查找字符串lpszString的Hash值。  

         int nHash = HashString(lpszString);      int nHashPos = nHash % nTableSize;  

   

         if ( lpTable[nHashPos].bExists  &&  !strcmp( lpTable[nHashPos].pString, lpszString ) )   

         {         

                  return nHashPos;    //返回找到的Hash值  

         }   

         else  

         {  

                  return -1;    

         }   

}  

#endif

    看到此，我想大家都在想一个很严重的问题：如果两个字符串在哈希表中对应的位置相同怎么办？毕竟一个数组容量是有限的，这种可能性很大。

    Blizzard的程序员使用精妙的方法。基本原理就是：他们在哈希表中不是用一个哈希值而是用三个哈希值来校验字符串。

 

    MPQ 使用的哈希表的格式与正常的哈希表有一些不同。它没有把实际的文件名存储在表中用于验证，实际上它根本就没有存储文件名。而是使用了3种不同的哈希：一个用于哈希表的下标，两个用于验证。这两个验证哈希替代了实际文件名。

    假如说两个不同的字符串经过一个哈希算法得到的入口点一致有可能，但用三个不同的哈希算法算出的入口点都一致，那几乎可以肯定是不可能的事了。当然了，这样仍然会出现2个不同的文件名哈希到3个同样的哈希。但是这种情况发生的概率平均是：1:18889465931478580854784，这个概率对于任何人来说应该都是足够小的。现在再回到数据结构上，Blizzard使用的哈希表没有使用链表，而采用"顺延"的方式来解决问题。

4：函数GetHashTablePos中，lpszString 为要在hash表中查找的字符串；lpTable 为存储字符串hash值的hash表；nTableSize为hash表的长度： 

 

int GetHashTablePos( char *lpszString, MPQHASHTABLE *lpTable, int nTableSize )  

{  

         const int  HASH_OFFSET = 0, HASH_A = 1, HASH_B = 2;  

   

         int  nHash = HashString( lpszString, HASH_OFFSET );  

         int  nHashA = HashString( lpszString, HASH_A );  

         int  nHashB = HashString( lpszString, HASH_B );  

         int  nHashStart = nHash % nTableSize;  

         int  nHashPos = nHashStart;  

   

         while ( lpTable[nHashPos].bExists )  

         {  

                  if (lpTable[nHashPos].nHashA == nHashA && lpTable[nHashPos].nHashB == nHashB )  

                  {  

                           return nHashPos;  

                  }  

                  else  

                  {  

                          nHashPos = (nHashPos + 1) % nTableSize;  

                  }  

   

                  if (nHashPos == nHashStart)  

                          break;  

         }  

         return -1;  

}  

   

上述程序解释：

    1计算出字符串的三个哈希值（一个用来确定位置，另外两个用来校验)

    2察看哈希表中的这个位置

    3哈希表中这个位置为空吗？如果为空，则肯定该字符串不存在，返回-1。

    4如果存在，则检查其他两个哈希值是否也匹配，如果匹配，则表示找到了该字符串，返回其Hash值。

    5移到下一个位置，如果已经移到了表的末尾，则反绕到表的开始位置起继续查询　

    6看看是不是又回到了原来的位置，如果是，则返回没找到

    7回到3。

 

三：哈希表大小

    哈希表的数组是定长的，如果太大，则浪费，如果太小，体现不出效率。合适的数组大小是哈希表的性能的关键。

    哈希表的尺寸最好是一个质数。当然，根据不同的数据量，会有不同的哈希表的大小。对于数据量时多时少的应用，最好的设计是使用动态可变尺寸的哈希表，那么如果你发现哈希表尺寸太小了，比如其中的元素是哈希表尺寸的2倍时，我们就需要扩大哈希表尺寸，一般是扩大一倍。

    下面是哈希表尺寸大小的可能取值：

    17, 37, 79, 163, 331, 673, 1361, 2729, 5471,10949, 21911, 43853, 87719, 175447, 350899, 701819, 1403641, 2807303, 5614657, 11229331,22458671, 44917381, 89834777, 179669557, 359339171, 718678369, 1437356741, 2147483647

```

### 死锁是什么？如何避免死锁
```
避免死锁的几种方式：

    设置加锁顺序

    设置加锁时限

    死锁检测

设置加锁顺序（线程按照一定的顺序加锁）：

死锁发生在多个线程需要相同的锁,但是获得不同的顺序。

假如一个线程需要锁，那么他必须按照一定得顺序获得锁。
例如加锁顺序是A->B->C，现在想要线程C想要获取锁，那么他必须等到线程A和线程B获取锁之后才能轮到他获取。（排队执行，获取锁）

缺点：
按照顺序加锁是一种有效的死锁预防机制。但是，这种方式需要你事先知道所有可能会用到的锁，并知道他们之间获取锁的顺序是什么样的。
设置加锁时限：（超时重试）

在获取锁的时候尝试加一个获取锁的时限，超过时限不需要再获取锁，放弃操作（对锁的请求。）。

若一个线程在一定的时间里没有成功的获取到锁，则会进行回退并释放之前获取到的锁，然后等待一段时间后进行重试。在这段等待时间中其他线程有机会尝试获取相同的锁，这样就能保证在没有获取锁的时候继续执行比的事情。

缺点：
但是由于存在锁的超时，通过设置时限并不能确定出现了死锁，每种方法总是有缺陷的。有时为了执行某个任务。某个线程花了很长的时间去执行任务，如果在其他线程看来，可能这个时间已经超过了等待的时限，可能出现了死锁。

在大量线程去操作相同的资源的时候，这个情况又是一个不可避免的事情，比如说，现在只有两个线程，一个线程执行的时候，超过了等待的时间，下一个线程会尝试获取相同的锁，避免出现死锁。但是这时候不是两个线程了，可能是几百个线程同时去执行，大的基数让事件出现的概率变大，假如线程还是等待那么长时间，但是多个线程的等待时间就有可能重叠，因此又会出现竞争超时，由于他们的超时发生时间正好赶在了一起，而超时等待的时间又是一致的，那么他们下一次又会竞争，等待，这就又出现了死锁。
死锁检测：

当一个线程获取锁的时候，会在相应的数据结构中记录下来，相同下，如果有线程请求锁，也会在相应的结构中记录下来。当一个线程请求失败时，需要遍历一下这个数据结构检查是否有死锁产生。

例如：线程A请求锁住一个方法1，但是现在这个方法是线程B所有的，这时候线程A可以检查一下线程B是否已经请求了线程A当前所持有的锁，像是一个环，线程A拥有锁1，请求锁2，线程B拥有锁2，请求锁1。
当遍历这个存储结构的时候，如果发现了死锁，一个可行的办法就是释放所有的锁，回退，并且等待一段时间后再次尝试。

缺点：
这个这个方法和上面的超时重试的策略是一样的。但是在大量线程的时候问题还是会出现和设置加锁时限相同的问题。每次线程之间发生竞争。
还有一种解决方法是设置线程优先级，这样其中几个线程回退，其余的线程继续保持着他们获取的锁，也可以尝试随机设置优先级，这样保证线程的执行。

参考引用：http://ifeve.com/deadlock-prevention/


教科书般的回答应该是，结合“哲学家就餐[1]”模型，分析并总结出以下死锁的原因，最后得出“避免死锁就是破坏造成死锁的，若干条件中的任意一个”的结论。

造成死锁必须达成的4个条件（原因）：

    互斥条件：一个资源每次只能被一个线程使用。
    请求与保持条件：一个线程因请求资源而阻塞时，对已获得的资源保持不放。
    不剥夺条件：线程已获得的资源，在未使用完之前，不能强行剥夺。
    循环等待条件：若干线程之间形成一种头尾相接的循环等待资源关系。

但是，“哲学家就餐”光看名字就很讨厌，然后以上这4个条件看起来也很绕口，再加上笔者又是个懒人，所以要让我在面试时把这些“背诵”出来实在是太难了！必须要想办法把这4个条件简化一下！
于是，通过对4个造成死锁的条件进行逐条分析，我们可以得出以下4个结论。

    互斥条件 ---> 独占锁的特点之一。
    请求与保持条件 ---> 独占锁的特点之一，尝试获取锁时并不会释放已经持有的锁
    不剥夺条件 ---> 独占锁的特点之一。
    循环等待条件 ---> 唯一需要记忆的造成死锁的条件。

不错！复杂的死锁条件经过简化，现在需要记忆的仅只有独占锁与第四个条件而已。

所以，面对如何避免死锁这个问题，我们只需要这样回答！
: 在并发程序中，避免了逻辑中出现复数个线程互相持有对方线程所需要的独占锁的的情况，就可以避免死锁。

作者：给你添麻烦了
链接：https://www.jianshu.com/p/44125bb12ebf
來源：简书
简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。

```

### TCP和UDP的最完整的区别
```
TCP UDP
TCP与UDP基本区别
  1.基于连接与无连接
  2.TCP要求系统资源较多，UDP较少； 
  3.UDP程序结构较简单 
  4.流模式（TCP）与数据报模式(UDP); 
  5.TCP保证数据正确性，UDP可能丢包 
  6.TCP保证数据顺序，UDP不保证 
　　
UDP应用场景：
  1.面向数据报方式
  2.网络数据大多为短消息 
  3.拥有大量Client
  4.对数据安全性无特殊要求
  5.网络负担非常重，但对响应速度要求高
 
具体编程时的区别
   1.socket()的参数不同 
　　 2.UDP Server不需要调用listen和accept 
　　 3.UDP收发数据用sendto/recvfrom函数 
　　 4.TCP：地址信息在connect/accept时确定 
　　 5.UDP：在sendto/recvfrom函数中每次均 需指定地址信息 
　　 6.UDP：shutdown函数无效
 
编程区别
   通常我们在说到网络编程时默认是指TCP编程，即用前面提到的socket函数创建一个socket用于TCP通讯，函数参数我们通常填为SOCK_STREAM。即socket(PF_INET, SOCK_STREAM, 0)，这表示建立一个socket用于流式网络通讯。 
　  SOCK_STREAM这种的特点是面向连接的，即每次收发数据之前必须通过connect建立连接，也是双向的，即任何一方都可以收发数据，协议本身提供了一些保障机制保证它是可靠的、有序的，即每个包按照发送的顺序到达接收方。 

　　而SOCK_DGRAM这种是User Datagram Protocol协议的网络通讯，它是无连接的，不可靠的，因为通讯双方发送数据后不知道对方是否已经收到数据，是否正常收到数据。任何一方建立一个socket以后就可以用sendto发送数据，也可以用recvfrom接收数据。根本不关心对方是否存在，是否发送了数据。它的特点是通讯速度比较快。大家都知道TCP是要经过三次握手的，而UDP没有。 

基于上述不同，UDP和TCP编程步骤也有些不同，如下：

TCP: 
TCP编程的服务器端一般步骤是： 
　　1、创建一个socket，用函数socket()； 
　　2、设置socket属性，用函数setsockopt(); * 可选 
　　3、绑定IP地址、端口等信息到socket上，用函数bind(); 
　　4、开启监听，用函数listen()； 
　　5、接收客户端上来的连接，用函数accept()； 
　　6、收发数据，用函数send()和recv()，或者read()和write(); 
　　7、关闭网络连接； 
　　8、关闭监听； 

TCP编程的客户端一般步骤是： 
　　1、创建一个socket，用函数socket()； 
　　2、设置socket属性，用函数setsockopt();* 可选 
　　3、绑定IP地址、端口等信息到socket上，用函数bind();* 可选 
　　4、设置要连接的对方的IP地址和端口等属性； 
　　5、连接服务器，用函数connect()； 
　　6、收发数据，用函数send()和recv()，或者read()和write(); 
　　7、关闭网络连接；

UDP:
与之对应的UDP编程步骤要简单许多，分别如下： 
　　UDP编程的服务器端一般步骤是： 
　　1、创建一个socket，用函数socket()； 
　　2、设置socket属性，用函数setsockopt();* 可选 
　　3、绑定IP地址、端口等信息到socket上，用函数bind(); 
　　4、循环接收数据，用函数recvfrom(); 
　　5、关闭网络连接； 

UDP编程的客户端一般步骤是： 
　　1、创建一个socket，用函数socket()； 
　　2、设置socket属性，用函数setsockopt();* 可选 
　　3、绑定IP地址、端口等信息到socket上，用函数bind();* 可选 
　　4、设置对方的IP地址和端口等属性; 
　　5、发送数据，用函数sendto(); 
　　6、关闭网络连接；

TCP和UDP是OSI模型中的运输层中的协议。TCP提供可靠的通信传输，而UDP则常被用于让广播和细节控制交给应用的通信传输。

UDP补充：
   UDP不提供复杂的控制机制，利用IP提供面向无连接的通信服务。并且它是将应用程序发来的数据在收到的那一刻，立刻按照原样发送到网络上的一种机制。即使是出现网络拥堵的情况下，UDP也无法进行流量控制等避免网络拥塞的行为。此外，传输途中如果出现了丢包，UDO也不负责重发。甚至当出现包的到达顺序乱掉时也没有纠正的功能。如果需要这些细节控制，那么不得不交给由采用UDO的应用程序去处理。换句话说，UDP将部分控制转移到应用程序去处理，自己却只提供作为传输层协议的最基本功能。UDP有点类似于用户说什么听什么的机制，但是需要用户充分考虑好上层协议类型并制作相应的应用程序。

TCP补充：
  TCP充分实现了数据传输时各种控制功能，可以进行丢包的重发控制，还可以对次序乱掉的分包进行顺序控制。而这些在UDP中都没有。此外，TCP作为一种面向有连接的协议，只有在确认通信对端存在时才会发送数据，从而可以控制通信流量的浪费。TCP通过检验和、序列号、确认应答、重发控制、连接管理以及窗口控制等机制实现可靠性传输。


TCP与UDP区别总结：
1、TCP面向连接（如打电话要先拨号建立连接）;UDP是无连接的，即发送数据之前不需要建立连接
2、TCP提供可靠的服务。也就是说，通过TCP连接传送的数据，无差错，不丢失，不重复，且按序到达;UDP尽最大努力交付，即不保   证可靠交付
3、TCP面向字节流，实际上是TCP把数据看成一连串无结构的字节流;UDP是面向报文的
  UDP没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如IP电话，实时视频会议等）
4、每一条TCP连接只能是点到点的;UDP支持一对一，一对多，多对一和多对多的交互通信
5、TCP首部开销20字节;UDP的首部开销小，只有8个字节
6、TCP的逻辑通信信道是全双工的可靠信道，UDP则是不可靠信道

```

###  五种I/O模型介绍一下 
```
https://segmentfault.com/a/1190000007355931
出处

阻塞 IO, 非阻塞 IO, 同步 IO, 异步 IO 这些术语相信有不少朋友都也不同程度的困惑吧? 我原来也是, 什么同步非阻塞 IO, 异步非阻塞 IO 的, 搞的头都大了. 后来仔细读了一遍
《UNIX 网络编程卷一 套接字联网 API(第三版)》的 6.2 章节, 终于把这些名词搞懂了.

下面我以《UNIX 网络编程卷一 套接字联网 API(第三版)》的 6.2 章节的内容为准, 整理了一下各种网络 IO 模型具体定义以及一些容易混淆的地方.
简介

Unix 下有 5 种可用的 IO 模型, 分别是:

    阻塞式 I/O

    非阻塞式 I/O

    I/O 复用(select 和 poll)

    信号驱动式 I/O (SIGIO)

    异步 I/O (POSIX 的 aio_系列函数)

阻塞式 I/O 模型

最流行的 IO 操作是阻塞式 IO(Blocking IO). 以 UDP 数据报套接字为例, 下图是其阻塞 IO 的调用过程:

clipboard.png

在上图中, 进程调用 recvfrom, 其系统调用直到数据报返回并且被复制到应用进程的缓冲区中 或者发送错误时才返回. 因此进程在调用 recvfrom 开始到它返回的整段时间内都是被阻塞的.
非阻塞式 IO(Non-Blocking IO)

进程把一个套接字设置为非阻塞是在通知内核: 当调用线程所请求的 IO 操作需要调用线程休眠来等待操作完成时, 此时不要将调用线程休眠, 而是返回一个错误.

clipboard.png

如上图所示, 前三次调用 recvfrom 时, 没有数据可返回, 因此内核转而立即返回一个 EWOULDBLOCK 错误. 第四次调用 recvfrom 时, 已经有数据了, 此时, recvfrom 会阻塞住, 等待内核将数据赋值到应用进程的缓冲区中, 然后再返回.(注意, 当有数据时, recvfrom 是阻塞的, 它会等待内核将数据复制到应用进程的缓冲区后, 才返回).
当一个应用进程像这样对一个非阻塞描述符循环调用 recvfrom 时, 我们称之为轮询(polling). 应用进程持续轮询内核, 以查看某个操作是否完成, 这么做会消耗大量的 CPU 时间, 不过这种模型偶尔也会遇到, 通常是专门提供某一种功能的系统中才有.
IO 复用模型

有了 IO 复用(IO multiplexing), 我们就可以调用 select 或 poll, 阻塞在这两个系统调用中的某一个之上, 而不是阻塞在真正的 IO 系统调用上. 例如:

clipboard.png

如上图所示, 当调用了 select 后, select 会阻塞住, 等待数据报套接字变为可读. 当 select 返回套接字可读这一条件时, 我们就可以调用 recvfrom 把所读取的数据报复制到应用进程缓冲区.
对比阻塞式 IO, IO 复用模型优势并不明显, 并且从使用方式来说, IO 复用模型还需要多调用一次 select, 因此从易用性上来说, 比阻塞式 IO 还略有不足. 不过 select 的杀手锏在于它可以监听多个文件描述符, 大大减小了阻塞线程的个数.
信号驱动 IO 模型

clipboard.png

信号驱动模型如上图所示. 当文件描述符就绪时, 我们可以让内核以信号的方式通知我们.
我们首先需要开启套接字的信号驱动式 IO 功能, 并通过 sigaction 系统调用安装一个信号处理函数. sigaction 系统调用是异步的, 它会立即返回. 当有数据时, 内核会给此进程发送一个 SIGIO 信号, 进而我们的信号处理函数就会被执行, 我们就可以在这个函数中调用 recvfrom 读取数据.
异步 IO 模型

异步 IO (asynchronous IO) 由 POSIX 规范定义, 在 POSIX 中定义了若干个异步 IO 的操作函数. 这个函数的工作原理是: 告知内核启动某个动作, 并让内核在整个操作(包括将数据从内核复制到应用进程缓冲区)完成后通知我们的应用进程.
异步 IO 模型和信号驱动的 IO 模型的主要区别在于: 信号驱动 IO 是由内核通知我们何时可以启动一个 IO 操作, 而异步 IO 模型是由内核通知我们 IO 操作何时完成.
异步 IO 模型的操作过程如图所示:

clipboard.png

当我们调用 aio_read 函数时(POSIX 异步 IO 函数以 aio_或 lio_ 开头), 给内核传递描述符, 缓冲区指针, 缓冲区大小(和 read 相同的三个参数) 和文件偏移(以 lseek 类似), 并告诉内核当整个操作完成时如何通知应用进程. 该系统调用立即返回, 而且在等待 IO 完成期间, 应用进程不被阻塞.
各种 IO 模型的比较

clipboard.png

如图所示, 上述五中 IO 模型中, 前四种模型(阻塞 IO, 非阻塞 IO, IO 复用, 信号驱动 IO)的主要区别在于第一阶段, 因为他们的第二阶段是一样的: 在数据从内核复制到调用者的缓冲区期间, 进程阻塞于 recvfrom 调用. 而第五种, 即异步 IO 模型中, 两个阶段都不需要应用进程处理, 内核为我们处理好了数据的等待和数据的复制过程.
关于同步 IO 和异步 IO

根据 POSIX 定义:

    A synchronous I/O operation causes the requesting process to be blocked until that I/O operation completes(导致请求进程阻塞, 直到 IO 操作完成).

    An asynchronous I/O operation does not cause the requesting process to be blocked(不导致请求进程阻塞).
    根据上述定义, 我们的前四种模型: 阻塞 IO 模型, 非阻塞 IO 模型, IO 复用模型和信号驱动 IO 模型都是同步 IO 模型, 因为其中真正的 IO 操作(recvfrom 调用) 会阻塞进程(因为当有数据时, recvfrom 会阻塞等待内核将数据从内核空间复制到应用进程空间, 当赋值完成后, recvfrom 才返回.) 只有异步 IO 模型与 POSIX 定义的异步 IO 相匹配.

总结

在处理网络 IO 操作时, 阻塞和非阻塞 IO 都是同步 IO.
只有调用了特殊的 API 才是异步 IO.

clipboard.png

因此网上常说的 "同步阻塞 IO", "同步非阻塞 IO" 其实就是阻塞 IO 模型和非阻塞 IO 模型, 因为阻塞 IO 和非阻塞 IO 模型都是同步的, 加了 "同步" 二字其实是多余了.
网络上常说的 "异步非阻塞 IO" 其实就是异步 IO 模型.

```

### 判断两个链表是否相交并找出交点
```
https://blog.csdn.net/jiqiren007/article/details/6572685

仔细研究两个链表，如果他们相交的话，那么他们最后的一个节点一定是相同的，否则是不相交的。因此判断两个链表是否相交就很简单了，分别遍历到两个链表的尾部，然后判断他们是否相同，如果相同，则相交；否则不相交。示意图如下：

判断出两个链表相交后就是判断他们的交点了。假设第一个链表长度为len1，第二个问len2，然后找出长度较长的，让长度较长的链表指针向后移动|len1 - len2| (len1-len2的绝对值)，然后在开始遍历两个链表，判断节点是否相同即可。


```

###  C++ map,set内部数据结构

```
C++ map,set内部数据结构

1 ）Set是一种关联容器，它用于存储数据，并且能从一个数据集合中取出数据。它的每个元素的值必须唯一，而且系统会根据该值来自动将数据排序。每个元素的值不能直接被改变。【重点】内部结构采用红黑树的平衡二叉树。multiset 跟set 类似，唯一的区别是允许键值重复！！！

如： 为何map和set的插入删除效率比用其他序列容器高？

为何每次insert之后，以前保存的iterator不会失效？

为何map和set不能像vector一样有个reserve函数来预分配数据？

当数据元素增多时（10000到20000个比较），map和set的插入和搜索速度变化如何？

或许有得人能回答出来大概原因，但要彻底明白，还需要了解STL的底层数据结构。 C++ STL 之所以得到广泛的赞誉，也被很多人使用，不只是提供了像vector, string, list等方便的容器，更重要的是STL封装了许多复杂的数据结构算法和大量常用数据结构操作。vector封装数组，list封装了链表，map和 set封装了二叉树等，在封装这些数据结构的时候，STL按照程序员的使用习惯，以成员函数方式提供的常用操作，如：插入、排序、删除、查找等。让用户在 STL使用过程中，并不会感到陌生。 C++ STL中标准关联容器set, multiset, map, multimap内部采用的就是一种非常高效的平衡检索二叉树：红黑树，也成为RB树(Red-Black Tree)。RB树的统计性能要好于一般的平衡二叉树(有些书籍根据作者姓名，Adelson-Velskii和Landis，将其称为AVL-树)，所以被STL选择作为了关联容器的内部结构。本文并不会介绍详细AVL树和RB树的实现以及他们的优劣，关于RB树的详细实现参看红黑树: 理论与实现(理论篇)。本文针对开始提出的几个问题的回答，来向大家简单介绍map和set的底层数据结构。

为何map和set的插入删除效率比用其他序列容器高？ 大部分人说，很简单，因为对于关联容器来说，不需要做内存拷贝和内存移动。说对了，确实如此。map和set容器内所有元素都是以节点的方式来存储，其节点结构和链表差不多，指向父节点和子节点。

  结构图可能如下：

       A

      /  /

    B    C

   / /   / /

  D  E F  G

因此插入的时候只需要稍做变换，把节点的指针指向新的节点就可以了。删除的时候类似，稍做变换后把指向删除节点的指针指向其他节点就OK了。这里的一切操作就是指针换来换去，和内存移动没有关系。 为何每次insert之后，以前保存的iterator不会失效？

看见了上面答案的解释，你应该已经可以很容易解释这个问题。iterator这里就相当于指向节点的指针，内存没有变，指向内存的指针怎么会失效呢(当然被删除的那个元素本身已经失效了)。相对于vector来说，每一次删除和插入，指针都有可能失效，调用push_back在尾部插入也是如此。因为为了保证内部数据的连续存放，iterator指向的那块内存在删除和插入过程中可能已经被其他内存覆盖或者内存已经被释放了。即使时push_back的时 候，容器内部空间可能不够，需要一块新的更大的内存，只有把以前的内存释放，申请新的更大的内存，复制已有的数据元素到新的内存，最后把需要插入的元素放 到最后，那么以前的内存指针自然就不可用了。特别时在和find等算法在一起使用的时候，牢记这个原则：不要使用过期的iterator。

为何map和set不能像vector一样有个reserve函数来预分配数据？ 我以前也这么问，究其原理来说时，引起它的原因在于在map和set内部存储的已经不是元素本身了，而是包含元素的节点。也就是说map内部使用的Alloc并不是map声明的时候从参数中传入的Alloc。例如： map, Alloc > intmap; 这时候在intmap中使用的allocator并不是Alloc, 而是通过了转换的Alloc，具体转换的方法时在内部通过Alloc::rebind重新定义了新的节点分配器，详细的实现参看彻底学习STL中的Allocator。其实你就记住一点，在map和set内面的分配器已经发生了变化，reserve方法你就不要奢望了。 当数据元素增多时（10000和20000个比较），map和set的插入和搜索速度变化如何？

如果你知道log2的关系你应该就彻底了解这个答案。在map和set中查找是使用二分查找，也就是说，如果有16个元素，最多需要比较4次就能找到结果，有32个元素，最多比较5次。那么有10000个呢？最多比较的次数为log10000，最多为14次，如果是20000个元素呢？最多不过15次。

看见了吧，当数据量增大一倍的时候，搜索次数只不过多了1次，多了1/14的搜索时间而已。你明白这个道理后，就可以安心往里面放入元素了。 最后，对于map和set Winter还要提的就是它们和一个c语言包装库的效率比较。在许多unix和linux平台下，都有一个库叫isc，里面就提供类似于以下声明的函数:

  void tree_init(void **tree);
  void *tree_srch(void **tree, int (*compare)(), void *data);
  void tree_add(void **tree, int (*compare)(), void *data, void (*del_uar)());
  int tree_delete(void **tree, int (*compare)(), void *data,void (*del_uar)());
  int tree_trav(void **tree, int (*trav_uar)());
  void tree_mung(void **tree, void (*del_uar)()); 

许多人认为直接使用这些函数会比STL map速度快，因为STL map中使用了许多模板什么的。其实不然，它们的区别并不在于算法，而在于内存碎片。如果直接使用这些函数，你需要自己去new一些节点，当节点特别多， 而且进行频繁的删除和插入的时候，内存碎片就会存在，而STL采用自己的Allocator分配内存，以内存池的方式来管理这些内存，会大大减少内存碎 片，从而会提升系统的整体性能。Winter在自己的系统中做过测试，把以前所有直接用isc函数的代码替换成map，程序速度基本一致。当时间运行很长 时间后（例如后台服务程序），map的优势就会体现出来。从另外一个方面讲，使用map会大大降低你的编码难度，同时增加程序的可读性。何乐而不为？

```

### STL 优缺点

```

作者：姚冬
链接：https://www.zhihu.com/question/20201972/answer/41324520
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

1. 代码膨胀问题每一个实例化过的模板类，都会膨胀出一份独立的代码，比如std::vector<std::string>, std::vector<int>，编译后会产生两份代码，在VC2008下，每份代码大约是3-4kb，这是因为vector比较简单代码少，如果是map则会产生30-50kb的代码，因为map里有个复杂的红黑树。对于数据处理类的代码里一般会定义很多种不同的结构体，不同的结构体放到不同的容器里，就会实例化出很多个类的代码，我见过一个项目里，这样的vector就有数百个。2. 内存使用效率问题 （以vc++2008为例）stl在内存使用效率上是比较低效的，比如std::string，它的sizeof大概是28，因为它有一个内置的16字节数组，用来做小字符串优化的，就是说低于16字节的字符串都会至少占用28字节内存，如果刚好17字节字符串，则会占用28字节+额外分配的字符串内存，额外分配的内存是一个堆块，又有很多浪费，相比用一个char *存储字符串大约多占用了一倍内存。还有map<>，每一个map的node都是一块独立分配的内存，如果是 map<int, int>呢，那就很悲剧了，为了存一个int要消耗几十个字节，很浪费的。如果元素数量有百万级，那么内存占用就很可观了，这种情况下建议自己实现allocator，做内存池。3. deep copy问题让两个容器的实例做赋值操作，看起来就一条语句，实际上容器里的每个元素都执行了一次赋值操作。如果容器里有百万级的数据，那么一个等号就产生了几百万次的构造和析构。传递参数的时候一定要用 const 引用，赋值可以用 swap代替。4. 隐式类型转换比如 有个函数void doSomething(const std::string &str);调用的时候   doSomething("hello");能编译执行，但是会产生一个临时的匿名的std::string实例，把"hello"复制一遍，然后在调用完成后析构掉。如果这个发生在循环体内部有可能影响性能。以上这些问题，在小程序里或者数据规模不大的时候，比如容器内元素只有几千这个规模，都不是什么大问题，那时开发效率才是重点，但是一旦有大数据stl容器会成为性能瓶颈的。我并不是主张不用STL，而是要充分了解STL的优缺点，根据应用场景做选择。


作者：知乎用户
链接：https://www.zhihu.com/question/20201972/answer/30182504
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

stl甚至C++的某些特性，都是在某些情况下进行取舍的。脱离这些具体的开发环境和需求，是无法讨论这个问题的。MMORPG服务端开发时，对CPU和内存的控制是很严格的。单线程支撑2000个玩家，16FPS，分配给每个玩家每帧的CPU只有80000个cycle（2.4GHz）。一个敌我关系判断函数，一秒钟可以调用上千万次。一个小对象可以同时存在上千万个。我们的策略是主要对象不用stl map，而使用自制的对象容器，这个容器集内存管理、ID分配、对象查找、遍历等功能于一体，因为可以根据需求有针对性的优化，所以性能提升很多。100k个对象的情况下，insert和delete的开销是stl的20%，find是50%。但其实很多管理的对象数量在几千以下的情况时，各种操作频率每秒最多几百次的，为了方便也是使用stl map的。stl list很多地方也用，但是stl list有很大的欠缺，就是无法很高效的删除一个节点。所以凡是有此需求的地方，我们都使用自制的list。vector一般不用，因为和直接写数组比没啥优势。很多时候，对性能瓶颈做优化的时候，是要连数据结构一起优化的，会有很多特定的需求，这种时候一般都不会使用stl。我们的代码风格偏C，大量使用平铺式的内存布局，这样数据可以很方便的memcpy后进行网络发送，或者读写文件，不需要写很多蛋疼的序列化。这样的结构里就不能使用stl了。algorithm里面用的也很少，因为需求不大。因为很多具体的策略是某些算法的组合，使用标准算法来拼，会很麻烦。另外，碎片化也是一个考量，但是没有10年前那么明显了。我们有一种将一个对象的大多数数据，都存放在一个完整的内存布局中的倾向，不喜欢有指针到处指。一个是这样cache命中的效率会高很多，更重要的是这样统计内存开销的时候，很容易知道哪个类的开销大，我们只要将对象管理器里的数量乘上sizeof的结果就行了。服务器端的内存都是自己的，比如一般逻辑服务器32G，数据服务器72G，我们都会倾向于一启动就用到50%的内存，反正不用白不用。

在STL中，list是一个双向循环链表，所谓循环链表就是指链表的头部和尾部是连接在一起的，下面两段代码实现的功能是一样的，但是执行过程却有所不同：

    //第一种
    list<int> lst1;
    if (lst1.empty())
    {
        //do something
    }
     
    //第二种
    list<int>lst2;
    if (lst2.size() == 0)
    {
        //do something
    }

       上面两段代码执行的功能都一样的，都是判断list集合内是否有元素，但是实际运行的过程却有所不同。
       对于第一种方法，由于list是首尾相连的，因此lst1直接判断头部的下一个节点是否为NULL就知道list是否有节点了，其时间复杂度为O(1)；
       对于第二种方法，size()函数的作用是获取节点的个数，因此lst2会从头到尾遍历一次链表，以得到链表节点的个数，其时间复杂度为O(n)。
       可见，虽然代码量差不多，但是时间复杂度上却相去甚远，当节点数较多的时候，两种写法相差的时间会越加明显。因此，当需要判断list的是否存在节点时，强烈建议使用list的empty()函数。
       
仅仅是个选择的问题，都是STL，可能写出来的效率相差几倍；
熟悉以下条款，高效的使用STL；
当对象很大时，建立指针的容器而不是对象的容器

1）STL基于拷贝的方式的来工作，任何需要放入STL中的元素，都会被复制；
这也好理解，STL工作的容器是在堆内开辟的一块新空间，而我们自己的变量一般存放在函数栈或另一块堆空间中；为了能够完全控制STL自己的元素，为了能在自己的地盘随心干活；这就涉及到复制；
而如果复制的对象很大，由复制带来的性能代价也不小 ；
对于大对象的操作，使用指针来代替对象能消除这方面的代价；
2）只涉及到指针拷贝操作， 没有额外类的构造函数和赋值构造函数的调用；

vecttor <BigObj> vt1;
vt1.push_bach(myBigObj);

vecttor <BigObj* > vt2;
vt2.push_bach(new BigObj());

注意事项：
1）容器销毁前需要自行销毁指针所指向的对象；否则就造成了内存泄漏；
2）使用排序等算法时，需要构造基于对象的比较函数，如果使用默认的比较函数，其结果是基于指针大小的比较，而不是对象的比较；
用empty() 代替size()来检查是否为空

因为对于list，size()会遍历每一个元素来确定大小，时间复杂度 o（n），线性时间；而empty总是保证常数时间；
尽量用区间成员函数代替单元素操作

使用区间成员函数有以下好处：
1）更少的函数调用
2）更少的元素移动
3）更少的内存分配

例：将v2后半部的元素赋值给v1：
单元式操作：

for (vector<Widget>::const_iterator ci = v2.begin() + v2.size() / 2;
ci != v2.end();
++ci)
v1.push_back(*ci)

使用区间成员函数assign()：

v1.assign(v2.begin() + v2.size() / 2, v2.end()); 

使用reserver避免不必要的内存分配(for vector)

新增元素空间不够时，vector会进行如下操作：
1）分配当前空间的两倍空间；
2）将当前元素拷贝到新的空间中；
3）释放之前的空间；
4）将新值放入新空间指定位置；

如果预先知道空间的大小，预先分配了空间避免了重新分配空间和复制的代价；
注：reserve()只是修改了容量，并非大小，向vector中增加元素还是需要通过push_back加入；
使用有序的vector代替关联容器(阶段性的操作适用)

对阶段性操作的定义：
先做一系列插入、完成之后，后续操作都是查询；

在阶段性的操作下，使用vector有以下优势：
1）因为vector有序，关联容器带来的有序优势散失；
2）都是使用二分法查找的前提下，查询算法对连续的内存空间的访问要快于离散的空间；
在map的insert()和operator［］中仔细选择

插入时，insert效率高；因为operator会先探查是否存在这个元素，如果不存在就构造一个临时的，然后才涉及到赋值，多了一个临时对象的构造；
更新时，［］效率更高，insert会创造一个对象，然后覆盖一个原有对象；而［］是在原有的对象上直接赋值操作；

散列函数的默认比较函数是equal＿to，因为不需要保持有序；
尽量用算法替代手写的循环

1）效率相比手写更高；
STL的代码都是C++专家写出来的，专家写出来的代码在效率上很难超越；
除非我们放弃了某些特性来满足特定的需求，可能能快过stl；比如，基于特定场合下的编程，放弃通用性，可移植性；
2）不容易出错；
3）使用高层次思维编程
相比汇编而言，C是高级语言；一条C语言语句，用汇编写需要好几条；
同样的，在STL的世界中，我们也有高层次的术语：
高层次的术语：insert／find／for＿each（STL算法）
低层次的词汇：for ／while（C++语法）
用高层次术语来思考编程，会更简单；
尽量用成员函数代替同名的算法

1）基于效率考虑，成员函数知道自己这个容器和其他容器有哪些特有属性，能够利用到这些特性；而通用算法不可以；
2）对于关联容器，成员函数find基于等价搜索；而通用算法find基于相等来搜索；可能导致结果不一样；
使用函数对象代替裸函数作为算法的输入参数

因为内联，在函数对象的方式中，内联有效，而作为函数指针时，一般编译器都不会内联函数指针指向的函数；即使指定了inline；
比如：

inline bool doubleGreater(double d1, double d2)
{
    return dl > d2;
}
vector<double> v;
...
sort(v.begin(), v.end(), doubleGreater);

这个调用不是真的把doubleGreater传给sort，它传了一个doubleGreater的指针。
更好的方式是使用函数对象：

sort(v.begin(), v.end(), greater<double>())

注：《effcient c＋＋》中的实验结论，使用函数对象一般是裸函数的1.5倍，最多能快2倍多
选择合适的排序算法

需要排序前思考我们的必要需求，可能我们只是需要前多少个元素，这时并不需要使用sort这种线性时间的工具，性能消耗更少的parttition可能是更好的选择；
以下算法的效率从左到右依次递减：

partition > stable_partition / nth_element / patical_sort / sort / stable_sort

功能说明：
partition ：将集合分隔为满足和不满足某个标准两个区间；
stable_partition ：partition的稳定版本；
nth_element ：获取任意顺序的前N个元素；
patical_sort ：获取前N个元素，这个N个元素已排序；
sort：排序整个区间；
stable_sort：sort的稳定版本；
选择合适的容器

为什么vector不提供push_front()成员方法？因为效率太差，如果有太多从前面插入的需求，就不应该使用vector，而用list；
关心查找速度，首先应该考虑散列容器（非标准STL容器,如：unordered_map,unordered_set)；其次是排序的vector，然后是标准的关联容器；       
       
据我无责任小范围调查，有以下几种原因：嵌入式系统或专用系统。在这种系统中可能连像样的C++编译器都没有，STL更是无从用起操作系统内核。这个环境中往往缺乏必要的C++ Runtime支持，例如I/O、RTTI或Exception等，本来还有个EC++可以指望一下，不过这个标准似乎已经胎死腹中遗留系统。的确，有很多公司必须维护一大堆Win9x甚至DOS时代的程序，这些环境中能用的C++编译器或者STL实现一般都有很多问题，不堪大用团队能力。如果你招了一群不会C++的程序员，当然没法在下个项目里用。FUD受害者。很多名人，包括Linus，都发表过一些针对C++/STL的言论，然后这些言论被网站转载，但是出于吸引眼球的目的，这些言论的背景和上下文都被有意忽略掉了，因为短口号总比长文章更有煽动性。不明真相的群众看到自己心目中的偶像们揭竿而起，自然赢粮景从领导不喜欢。嗯，这个的具体原因要问领导自己，不过真有这事儿，对不？

作者：徐辰
链接：https://www.zhihu.com/question/20201972/answer/15247408
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

作者：陈甫鸼
链接：https://www.zhihu.com/question/20201972/answer/23454845
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

最初开始禁用 C++ STL，更多地是早期项目编码实践中留下的惯例，被后来的程序员继承下来。老项目中这种选择尤其地多。不过如果有人将其上升到公司行为在不同项目中全面禁用 STL，则没有必要，而且我倾向于做这种决定的人并不理解 C++ 编译系统。一般来说，项目中禁用 C++ 多见于两种具体场景：或者项目的产出产品为函数库，或者需要引用第三方函数库。具体地来说，有三个主要原因：第一个原因是二进制边界混乱。对需要在项目中使用第三方函数库的程序员来说，二进制边界是个头痛的问题。C++ 在这一方面本身就处理得不算好，加上模板后起到的是雪上加霜的后果。没有经验的程序员会贪图方便而在公开头文件中使用 C++ 模板，如果这时调用方的编译器选项设置或 STL 版本和编译方不同，那么就可能出现同样的头文件在不同的环境下二进制布局不符的情况。——顺便说一句，在过去十年里，各个主流编译器附带的 STL 版本变化节奏不慢，所以这种由于编译环境不同而导致的 bug 并不算罕见，但缺乏汇编知识的用户难以排查。第二个原因是不愿使用异常。如今除了 Android 上的 STLPort 关闭异常，大部分主流 C++ STL 实现里都无法脱离异常使用 STL。异常带来的问题主要是两个：性能下降，代码膨胀。这几年 C++ 编译器在性能方面的改进很多，good path 的性能问题已经基本没有，但代码膨胀问题却没有太多改善，甚至这个性能问题的一部分解决方案就是以代码膨胀为代价。我写过一篇短文比对过 Android 上 gcc 4.6 在有无异常的情况下的汇编代码逻辑，可以看到，启动异常时生成的汇编代码量多出了相当一部分（我的例子中是 50%），用于处理各种隐含代码中的异常问题。这一条在手机系统中有时候会引起意想不到的麻烦，比如软件升级后导致 app 在低存储容量的手机中安装失败。顺便说一句，这个问题并不是 gcc 独有，clang 上生成的代码是一样的。参考：http://dummydigit.net/posts/2014-01-01-23-30-1.html。最后一个原因是 C 兼容。严格地说，STL 在这个问题上算是躺枪，这个坑在很多具体的场景中也是因为异常而引入，但这个问题的麻烦程度比前两个问题更高。比如 gcc 在编译纯 C 代码时默认关闭 -fexceptions 选项，因此这样编译出来的代码中没有异常处理相关的栈展开。如果某个 C++ 项目引用了一个第三方 C 项目，它很难确保那个 C 项目给出的二进制代码中正确进行了异常处理并保证代码服从异常安全操作。这种场景下混用 C/C++ ，就可能在抛出异常时莫名其妙地崩溃或者出现 C 代码区段中的资源泄漏，特别是 expat 那种大量利用回调的代码结构。要规避这种风险并非不可能，但需要 C 的架构部分做修改，比如使用 DOM 那种树形结构，这种做法对历史项目而言又很难办到。换言之，如果一个项目出于种种原因需要保持 C 兼容，而 STL 就属于其中一个不可控的变数，与其相信程序员不犯错，不如直接禁用更可控一些。参考：Code Gen Options要解决二进制相关的问题很简单：整个项目的所有相关代码在同一个代码基上编译，强制打开编译选项添加异常代码，并去除一切二进制依赖。但对很多小公司来说，引入这样的系统对配置管理的要求较高。如果一部分依赖关系来自自己并不了解的第三方代码，轻易修改编译选项可能带来的风险与第三方代码库的规模成正比。退一步说，即便团队里真的有强大的配置管理工程师能够搞定一切，他们也不会有能力解决代码膨胀问题，除非他们有权决定换一个编译器。相比之下，前面朋友所说的所谓性能或者编译出错时糟糕的可读性，在我看来反倒是次要因素，而且这些缺陷都正在新的编译器中逐步得到解决或改善，比如 clang。所以那些选择禁用 STL 的早期项目负责人，总有一些确实的理由，没有人那么别扭地想跟开发效率过不去。至于后来的人是真的仔细想过这些细节还是人云亦云，那是另一个问题。

作者：知乎用户
链接：https://www.zhihu.com/question/20201972/answer/21899611
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

随便吐槽几句，仅限游戏后端开发行业，请折叠。1，性能 
随着C++11标准在各大编译器的实现，有了move和rvalue，STL的性能不会是瓶颈，而且另一方面，既然程序要最高的性能，但选择了C++语言而不是C或者assemble，看来还是看重C++的抽象能力。所以性能是个伪命题。当然，也可以自己去实现一套STL的东西（比如EA就自己搞过一套EA STL），但要跟时代一起进化（新标准、新语言特性的引入），你要做很多benchmark写很多test case，有新用法了还要面临在老项目里的推广（最困难的部分），这些都是巨大的成本，有这时间少百分之几的性能又怎样，陪陪家人或者自己看看电影听听音乐读点书不挺好的吗？2，对STL不熟悉
如楼上已经有几位知友提到，server端的程序员大多是从C转过来的，对C++的一些高级特性(包括STL的实现)并没有很好的掌控能力，自然会选择用C的方式来用C++。这样确实让代码看起来更“易懂”了点，减少了一点C++语言复杂性带来的思维包袱，但根本上其实是在用C++里的一种C with class范式编程。3，调试我猜想STL不好调试的说法是源于debug版本里STL各种容器的begin(), end()会让开发者在调试的时候有很多step in操作。调试这个事情跟具体使用什么库没有太必然的联系，很多调试的书籍(软件调试 (豆瓣))也都是讲系统体系结构上知识。4，boostSTL都嫌弃的人是不可能用boost了，因为这boost里的东西比STL激进多了。

作者：fullsail
链接：https://www.zhihu.com/question/20201972/answer/41373087
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

大部分团队用C++不用STL是因为……，他们low。我在公司的BBS也曾经表达过类似观点，觉得STL性能不好的请把你们的代码拿出来，看我用STL实现出来的性能和你的代码比一下。但没办法，很多C++的程序员大部分对C++的理解就是带类的C，而且他们也不懂OOP。我这个问题的的原因分析是，大部分是因为懒，STL是有一定的学习门槛的和陷阱的，多学一点东西哪有打LOL好玩。而且更加悲剧的是中国的教学体制决定了。大部分毕业生程序员并不喜欢编程。而一些很老的程序员也固步自封，没法子改变他们的固有思维。前面有一位 @陈琳
 提到了在MS VC下用debug版本效率不高。请问这和STL有什么关系？居然还有这么多人点赞。请各位阅读一下《Windows 
程序调试》，VC为了调试安全做了多少事情，特别是内存管理这块，如果你反复构造STL对象，当然会效率低，但既然各位总把性能挂在嘴边。为啥要反复构
造，扩展STL对象？很多人在说STL的缺点，STL当然有缺点，但比起大部分程序员写的的代码。STL的好处真是……，如果你阅读过认真侯捷《STL源码剖析》，我想你对接口设计，模版，数据结构的认识都会有一些一个新的境界。但对于BOOST，我个人推荐不要实用，学习可以。过于重，而且很多东东在C++11的编译器上已经支持，没必要折腾。但中间很多模块，比如signal还是很值得看看的。对于应用开发，STL应该可以随便用。google的代码规范也是这样说的。部分内嵌系统的同学不用也可以理解。（其实现在不少内嵌系统的设备内存并不是问题）部分团队实用改写后的STL这个问题我到时很承认，我自己也干过不少，我就修过简化的放在共享内存实用的STL（在一块内存中使用，消灭指针）。但这个至少算STL的衍生把。最后我要声明，我说的是用C++，不是C，请别拿Linus大爷出来打我。但糟糕的是C语言更不合适菜鸟用。

作者：姚冬
链接：https://www.zhihu.com/question/20201972/answer/41324520
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

说几个STL的缺点吧，虽然都是在比较极端的情况下出现，但是对于一些大项目还是会遇到的1. 代码膨胀问题每一个实例化过的模板类，都会膨胀出一份独立的代码，比如std::vector<std::string>, std::vector<int>，编译后会产生两份代码，在VC2008下，每份代码大约是3-4kb，这是因为vector比较简单代码少，如果是map则会产生30-50kb的代码，因为map里有个复杂的红黑树。对于数据处理类的代码里一般会定义很多种不同的结构体，不同的结构体放到不同的容器里，就会实例化出很多个类的代码，我见过一个项目里，这样的vector就有数百个。2. 内存使用效率问题 （以vc++2008为例）stl在内存使用效率上是比较低效的，比如std::string，它的sizeof大概是28，因为它有一个内置的16字节数组，用来做小字符串优化的，就是说低于16字节的字符串都会至少占用28字节内存，如果刚好17字节字符串，则会占用28字节+额外分配的字符串内存，额外分配的内存是一个堆块，又有很多浪费，相比用一个char *存储字符串大约多占用了一倍内存。还有map<>，每一个map的node都是一块独立分配的内存，如果是 map<int, int>呢，那就很悲剧了，为了存一个int要消耗几十个字节，很浪费的。如果元素数量有百万级，那么内存占用就很可观了，这种情况下建议自己实现allocator，做内存池。3. deep copy问题让两个容器的实例做赋值操作，看起来就一条语句，实际上容器里的每个元素都执行了一次赋值操作。如果容器里有百万级的数据，那么一个等号就产生了几百万次的构造和析构。传递参数的时候一定要用 const 引用，赋值可以用 swap代替。4. 隐式类型转换比如 有个函数void doSomething(const std::string &str);调用的时候   doSomething("hello");能编译执行，但是会产生一个临时的匿名的std::string实例，把"hello"复制一遍，然后在调用完成后析构掉。如果这个发生在循环体内部有可能影响性能。以上这些问题，在小程序里或者数据规模不大的时候，比如容器内元素只有几千这个规模，都不是什么大问题，那时开发效率才是重点，但是一旦有大数据stl容器会成为性能瓶颈的。我并不是主张不用STL，而是要充分了解STL的优缺点，根据应用场景做选择。

作者：赵丙峰
链接：https://www.zhihu.com/question/20201972/answer/28520436
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

初步浏览下部分答案。如果知乎上的C++回答代表C++的中位数水平的话， C++现状不容乐观。我记得几年前有一个C++会议。Andrei Alexandrescu讲C++异常。有人问说公司不允许异常怎么办？Andrei给出的答案是换一家允许使用的公司。合格的C++程序员本来就稀缺，没必要在这样的环境下干活（大意），Shutter Herb似乎也在旁边，支持这一观点。而题主的问题是C++不允许使用STL怎么办。那您这是用C编程啊。窃以为C编程问题不合适挂到C++的头上问。如果异常的使用还有争论（其实是瞎整，有机会再说），STL的使用则毫无争议。如果你觉得有争议，要么不了解要解决的问题，要么不了解STL，或者二者都不了解。STL要比自己写的同样算法更高效（针对不同的类型做特化），更紧凑（没错！如果代码膨胀了，多半是误用STL，显示特化或者实例化可以完全消除这问题），更安全（标准化后的库级的质量）。STL展现的思想是基于模板的静态类型系统的一个极致。这也是为什么更多的主流语言加入模板支持的原因。C++对模板的支持语法上有点复杂， 语义上由于C++类型系统的不完备也略显冗余，但是其外部效果应该是完全达到了。按照Dr Stroustrup的说法（Element of Programming的评语），“... contains some of the most beautiful code I have ever seen.”

作者：知乎用户
链接：https://www.zhihu.com/question/20201972/answer/19840581
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

我公司也禁用STL,原因如下:STL: Standard Template Library : '标准'模板库没有银弹,既然有'标准'库,就必然有'不标准'的库,有标准的需求,就必然有不标准的需求,STL那么多结构,那么复杂的模板参数,一直目标就是把各种不太标准的需求让标准库能够实现,但是实现起来永远"别别扭扭",我想举几个工作中的例子:我想要一个线程安全的list,为了效率我想用lockfree的方式,STL没有lockfree,我只能在stl的queue外面套个锁.我想要一个内部不调用new和delete的固定尺寸的链表,STL可以实现吗? 可以的,我可以提前push一大堆元素,然后在这个list生存期内不再push和pop,然后通过迭代器迭代各个元素修改它们的值来实现固定尺寸的链表.我有个类X,一大堆X可以组成一个链表,然后X中有个函数可以实现将X从链表中任意位置删掉的方法,那么我可以用list<X>吗? 可以,但是这样做必须要给X重载个=操作符,那么用list<X*>就好了,可是这样一来就实现不了快速将X从链表中删掉的方法,其实也可以,那就是遍历一下链表找到对应的元素然后删掉,效率低了点,不过我可以在X中加个属性指向链表本身然后需要的时候调用X.myList->erase(X),然后这么做我还不知道安全不,于是我又要查各种资料...................以上我需要的功能,STL都可以实现,但只要你想要的东西非常'个性'或者和STL的思想有偏差,你就必须用一些别别扭扭的方法来'兼容'STL,最后产生的效果,就是低效和臃肿.那么上面我的需求,最好的办法怎么实现呢? 就是自己写一个lockfree的,自己写一个固定元素个数的侵入式链表,既不难,也直观,调试起来也不晕,更不用考虑内存泄露与否的问题.但是有人管这个,叫做"重新写轮子".重新写轮子当然是低效和没有意义的,问题是我们公司的应用,99%的情况下我需要的都不是'标准'的轮子,而是椭圆的轮子,带齿的轮子,螺旋桨或者一个平底锅.我当然可以通过压扁STL,打磨STL,加工STL或者给STL加个木头把儿来实现我想要的功能.但是我为什么不干脆自己做个椭圆轮子,带齿的轮子,螺旋桨和平底锅呢?面对更复杂的结构,更是如此,复杂的结构很可能是一段代码中的某个性能瓶颈,在结构相同的前提下,改善性能的一个大方面就是针对需求进行优化,可是STL恰恰很难针对需求进行优化,因为需求永远特殊,而STL是'标准'.所以一些公司禁用STL,是有道理的,有些公司爱用STL,也是有道理的,只不过有些项目足够'特殊',有些项目不足够特殊而已.完全看需求,不能一概而论.

作者：知乎用户
链接：https://www.zhihu.com/question/20201972/answer/30182504
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

tl甚至C++的某些特性，都是在某些情况下进行取舍的。脱离这些具体的开发环境和需求，是无法讨论这个问题的。MMORPG服务端开发时，对CPU和内存的控制是很严格的。单线程支撑2000个玩家，16FPS，分配给每个玩家每帧的CPU只有80000个cycle（2.4GHz）。一个敌我关系判断函数，一秒钟可以调用上千万次。一个小对象可以同时存在上千万个。我们的策略是主要对象不用stl map，而使用自制的对象容器，这个容器集内存管理、ID分配、对象查找、遍历等功能于一体，因为可以根据需求有针对性的优化，所以性能提升很多。100k个对象的情况下，insert和delete的开销是stl的20%，find是50%。但其实很多管理的对象数量在几千以下的情况时，各种操作频率每秒最多几百次的，为了方便也是使用stl map的。stl list很多地方也用，但是stl list有很大的欠缺，就是无法很高效的删除一个节点。所以凡是有此需求的地方，我们都使用自制的list。vector一般不用，因为和直接写数组比没啥优势。很多时候，对性能瓶颈做优化的时候，是要连数据结构一起优化的，会有很多特定的需求，这种时候一般都不会使用stl。我们的代码风格偏C，大量使用平铺式的内存布局，这样数据可以很方便的memcpy后进行网络发送，或者读写文件，不需要写很多蛋疼的序列化。这样的结构里就不能使用stl了。algorithm里面用的也很少，因为需求不大。因为很多具体的策略是某些算法的组合，使用标准算法来拼，会很麻烦。另外，碎片化也是一个考量，但是没有10年前那么明显了。我们有一种将一个对象的大多数数据，都存放在一个完整的内存布局中的倾向，不喜欢有指针到处指。一个是这样cache命中的效率会高很多，更重要的是这样统计内存开销的时候，很容易知道哪个类的开销大，我们只要将对象管理器里的数量乘上sizeof的结果就行了。服务器端的内存都是自己的，比如一般逻辑服务器32G，数据服务器72G，我们都会倾向于一启动就用到50%的内存，反正不用白不用。

作者：匿名用户
链接：https://www.zhihu.com/question/20201972/answer/24109335
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

new delete用起来都太奢侈了。 new/malloc语句返回时间无法确定，所以没有办法估算每一行代码的性能。所要主要业务路径是不会用new delete，资源都是预分配，从入品到出口，经过比TCP复杂的分包组包，重转，CRC校验，优先级排队等等，只有一次内存copy，就是从入口到出口。一个400MHz PowerPC + 128/256M内存就要处理几W条的话务量，一个不确定会造成后面灾难性的后果。所以高性能及高可靠性的场合，是不太可能用Boost/STL这些大库去完成小功能，这些特定条件，用这些通用库通常结果最差的。二：代码维护管理如果是长生命周期的软件，一般是不太喜欢用boost库或STL的。一般使用STL boost都是一些相对简单的数据结构或者算法场合，通常较大规模的开发，都会有自己底层库，比如类似std::string的string库，或者一些链表之类的，这一类自定义实现的库，简单，维护修改很方便。比如链表使用的通常是10多个成员，可以默认预分配足够的资源，减少分配删除的操作。或者对象都是某些固定的大小的，频繁插入删除的，内存块可以用自定义的内存池管理。复杂的算法或结构，那是软件核心所在。另外没有什么代码是没有BUG的，或者就算STL boost再怎么成熟稳定， 如果使用不当，简单的问题容易查，遇上复杂偶发的问题，行为记录通常是不可能的（比如记录一个软件连续运行多天的操作详细日志，可能就有几十G)，通常只能获取针对问题点关键一些数据结构来帮助分析。如果你的一引起基础数据构造在stl/boost上，这时能不能获取有效数据就很成问题了。在我看来，使用STL Boost在一些快餐之类产品上，比如网页游戏服务器，就几个月，或者长一点就一两年的上，的确是个不错的选择，尤其是一些规模相对小的团队，不用花时间来定制一些库。也不要求绝对可靠性。 偶次挂一次半次的，用少量RMB就能解决了，何必花大量人力物力查一个一两个月才出现一次影响用户只有一两个而且还不是VIP的用户的BUG. 而且通常可以有其他手段来回避问题，比如通过日志还原一些参数。

作者：ming li
链接：https://www.zhihu.com/question/20201972/answer/23658090
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

代码膨胀是一方面，在centos上面编译的c++的debug可执行程序居然有300MB，当时我就啊啊啊啊啊啊啊啊了。每写一个类X，就有可能出现vector<X>, list<X>, set<X>, map<?,X>等，组合爆炸后就非常恐怖了。stl会产生内存碎片，这个是听腾讯的同学说的他们不用的原因。另外在充分了解程序的负载数据量的情况下，用静态数组会更加高效。封装引起的低效。c++写OO就要有封装的思想，封装又有引入低效的可能。比如c里面一个对象，要同时存放于几个链表里面，当对象被删除的时候，可以以O（1）的效率从所有链表中把自己移除。但stl的list里面要封装容器存放对象的方式，外部只给你一个迭代器。这个对象如果以指针方式同时放在多个list里面，要删除的时候，只能把每个list遍历一次（别说你尝试保存迭代器这种危险行为），额外的遍历list的开销，就是封装带来的副作用，也会让stl显得“慢”。好的设计可以避免一些性能损耗，带总要为封装付出代价。各种隐藏的坑。比如map把，如果有个结构叫A，A的sizeof比较大，那么如果你尝试用map<?,A> 这种方式，让map管理A的析构，那么你就掉坑里了（虽然stl本意是这样，让stl容器放对象，但真正用起来的时候，绝大多数情况只用stl容器放指针）。这种情况下map的find操作要付出很高代价。


```



